"use client";

import {
  ConnectionStatus,
  CountdownOverlay,
  FlashOverlay,
  PhotoSelectionPanel,
  PhotoThumbnailGrid,
  ProcessingIndicator,
} from "@/components";
import { useChromaKey } from "@/hooks/useChromaKey";
import { useCompositeCanvas } from "@/hooks/useCompositeCanvas";
import { usePhotoCapture } from "@/hooks/usePhotoCapture";
import { useSignaling } from "@/hooks/useSignaling";
import { useWebRTC } from "@/hooks/useWebRTC";
import { useAppStore } from "@/lib/store";
import { getApiHeadersMultipart } from "@/lib/api";
import { downloadPhotoFrame } from "@/lib/frame-generator";
import { VideoRecorder, downloadVideo } from "@/lib/video-recorder";
import { splitVideo, downloadSegments, cleanupSegments, type VideoSegment } from "@/lib/video-splitter";
import { composeVideoGrid, downloadComposedVideo } from "@/lib/video-composer";
import { composeVideoWithWebGL, downloadWebGLComposedVideo, type VideoSource } from "@/lib/webgl-video-composer";
import { ASPECT_RATIOS, type AspectRatio } from "@/types";
import { useEffect, useRef, useState } from "react";
import { v4 as uuidv4 } from "uuid";

export default function HostPage() {
  const store = useAppStore();
  const { connect, sendMessage, on, off, isConnected } = useSignaling();
  const { localStream, remoteStream, startLocalStream, createOffer } =
    useWebRTC({ sendMessage, on });

  const [isCameraActive, setIsCameraActive] = useState(false);
  const [chromaKeyEnabled, setChromaKeyEnabled] = useState(true); // Default ON for VR
  const [sensitivity, setSensitivity] = useState(50);
  const [smoothness, setSmoothness] = useState(10);

  // Display options (flip horizontal)
  const [hostFlipHorizontal, setHostFlipHorizontal] = useState(false);
  const [guestFlipHorizontal, setGuestFlipHorizontal] = useState(false);

  // Aspect ratio settings (must be declared before usePhotoCapture)
  const [aspectRatio, setAspectRatio] = useState<AspectRatio>('16:9');

  // Photo capture state
  const [isCapturing, setIsCapturing] = useState(false);
  const [countdown, setCountdown] = useState<number | null>(null);
  const [showFlash, setShowFlash] = useState(false);
  const [peerSelectedPhotos, setPeerSelectedPhotos] = useState<number[]>([]);
  const [isGeneratingFrame, setIsGeneratingFrame] = useState(false);

  // Use shared photo capture hook
  const {
    photoCount,
    photos,
    isProcessing,
    captureAndUpload,
    resetCapture,
    setMergedPhotos,
    startProcessing,
  } = usePhotoCapture({
    roomId: store.roomId,
    userId: store.userId,
    aspectRatio: aspectRatio,
    onFlash: () => {
      setShowFlash(true);
      setTimeout(() => setShowFlash(false), 300);
    },
  });

  const localVideoRef = useRef<HTMLVideoElement>(null);
  const localCanvasRef = useRef<HTMLCanvasElement>(null);
  const remoteVideoRef = useRef<HTMLVideoElement>(null);
  const compositeCanvasRef = useRef<HTMLCanvasElement>(null);
  const initializedRef = useRef(false);
  const videoRecorderRef = useRef<VideoRecorder | null>(null);

  // Video recording state - Individual segments per photo
  const [recordedSegments, setRecordedSegments] = useState<VideoSegment[]>([]);
  const [currentlyRecording, setCurrentlyRecording] = useState<number | null>(null); // photoNumber being recorded

  // Video composition state
  const [composedVideo, setComposedVideo] = useState<{ blob: Blob; url: string } | null>(null);
  const [isComposing, setIsComposing] = useState(false);
  const [composeProgress, setComposeProgress] = useState('');

  // Timer settings
  const [recordingDuration, setRecordingDuration] = useState(10); // seconds
  const [captureInterval, setCaptureInterval] = useState(3); // seconds between photos

  // Use shared chroma key hook for local video
  useChromaKey({
    videoElement: localVideoRef.current,
    canvasElement: localCanvasRef.current,
    stream: localStream,
    enabled: chromaKeyEnabled,
    sensitivity,
    smoothness,
    width: ASPECT_RATIOS[aspectRatio].width,
    height: ASPECT_RATIOS[aspectRatio].height,
  });

  // Use shared composite canvas hook
  useCompositeCanvas({
    compositeCanvas: compositeCanvasRef.current,
    backgroundVideo: remoteVideoRef.current,
    foregroundCanvas: localCanvasRef.current,
    localStream,
    remoteStream,
    width: ASPECT_RATIOS[aspectRatio].width,
    height: ASPECT_RATIOS[aspectRatio].height,
    guestFlipHorizontal,
    hostFlipHorizontal,
  });

  // Initialize video recorder once
  useEffect(() => {
    if (!videoRecorderRef.current) {
      console.log('[Host] Creating VideoRecorder with canvas getter');
      videoRecorderRef.current = new VideoRecorder(() => compositeCanvasRef.current);
      console.log('[Host] VideoRecorder initialized with getter function');
    }
  }, []); // Initialize only once

  // Initialize
  useEffect(() => {
    if (initializedRef.current) return;
    initializedRef.current = true;

    const init = async () => {
      let userId = store.userId;
      if (!userId) {
        userId = uuidv4();
        store.setUserId(userId);
        console.log("[Host] userId:", userId);
      }

      try {
        await connect();
        console.log("[Host] Connected to signaling server");

        sendMessage({
          type: "join",
          roomId: "",
          userId,
          role: "host",
        });
      } catch (error) {
        console.error("[Host] Connection failed:", error);
        alert("ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
      }
    };

    init();
  }, []);

  // Start camera
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1920 },
          height: { ideal: 1080 },
        },
        audio: true,
      });

      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
      }

      await startLocalStream(() => Promise.resolve(stream));
      setIsCameraActive(true);
      console.log("[Host] Camera started");
    } catch (error) {
      console.error("[Host] Camera error:", error);
      alert("ì¹´ë©”ë¼ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
    }
  };

  // Stop camera
  const stopCamera = () => {
    if (localStream) {
      localStream.getTracks().forEach((track) => track.stop());
      setIsCameraActive(false);
    }
  };

  // Send chroma key settings to Guest
  const updateChromaKeySettings = (
    enabled: boolean,
    sens: number,
    smooth: number
  ) => {
    if (!store.roomId) return;

    sendMessage({
      type: "chromakey-settings",
      roomId: store.roomId,
      settings: {
        enabled,
        color: "green",
        similarity: sens,
        smoothness: smooth,
      },
    });
  };

  // Watch for chroma key changes and broadcast
  useEffect(() => {
    if (store.roomId && remoteStream) {
      updateChromaKeySettings(chromaKeyEnabled, sensitivity, smoothness);
    }
  }, [chromaKeyEnabled, sensitivity, smoothness, store.roomId, remoteStream]);

  // Toggle Host's display flip option
  const toggleHostFlip = () => {
    const newFlipState = !hostFlipHorizontal;
    setHostFlipHorizontal(newFlipState);

    // Broadcast to Guest
    if (store.roomId) {
      sendMessage({
        type: 'host-display-options',
        roomId: store.roomId,
        options: {
          flipHorizontal: newFlipState,
        },
      });
      console.log('[Host] Sent display options:', { flipHorizontal: newFlipState });
    }
  };

  // Update aspect ratio settings and broadcast
  const updateAspectRatio = (ratio: AspectRatio) => {
    setAspectRatio(ratio);

    if (store.roomId) {
      const settings = {
        ratio,
        width: ASPECT_RATIOS[ratio].width,
        height: ASPECT_RATIOS[ratio].height,
      };

      sendMessage({
        type: 'aspect-ratio-settings',
        roomId: store.roomId,
        settings,
      });

      console.log('[Host] Sent aspect ratio settings:', settings);
    }
  };

  // Setup remote video
  useEffect(() => {
    if (remoteStream && remoteVideoRef.current) {
      remoteVideoRef.current.srcObject = remoteStream;
      console.log("[Host] Remote stream connected");
    }
  }, [remoteStream]);

  // Listen to peer's photo selection
  useEffect(() => {
    const handlePhotoSelectSync = (message: any) => {
      console.log("[Host] Received peer photo selection:", message);
      const currentUserId = store.userId;
      if (message.userId !== currentUserId) {
        setPeerSelectedPhotos(message.selectedIndices);
      }
    };

    on("photo-select-sync", handlePhotoSelectSync);

    return () => {
      // Cleanup if needed
    };
  }, [on, store.userId]);

  // Listen to guest display options
  useEffect(() => {
    const handleGuestDisplayOptions = (message: any) => {
      console.log("[Host] Received guest display options:", message.options);
      if (message.options) {
        setGuestFlipHorizontal(message.options.flipHorizontal);
      }
    };

    on("guest-display-options", handleGuestDisplayOptions);

    return () => {
      // Cleanup if needed
    };
  }, [on]);

  // Listen to session settings broadcast from server
  useEffect(() => {
    const handleSessionSettings = (message: any) => {
      console.log("[Host] Received session settings broadcast from server:", message);
      if (message.settings) {
        console.log("[Host] Broadcast settings - recordingDuration:", message.settings.recordingDuration, "captureInterval:", message.settings.captureInterval);
      }
    };

    on("session-settings", handleSessionSettings);

    return () => {
      // Cleanup if needed
    };
  }, [on]);

  // Listen to video frame request from Guest
  useEffect(() => {
    const handleVideoFrameRequest = async (message: any) => {
      console.log('[Host] Received video frame request:', message);

      if (message.selectedPhotos && message.selectedPhotos.length === 4) {
        console.log('[Host] Auto-composing video frame for photos:', message.selectedPhotos);

        // Update peer selected photos
        setPeerSelectedPhotos(message.selectedPhotos);

        // Auto-compose and upload video
        await autoComposeAndUploadVideo(message.selectedPhotos);
      }
    };

    on('video-frame-request', handleVideoFrameRequest);

    return () => {
      // Cleanup if needed
    };
  }, [on, recordedSegments, recordingDuration, captureInterval]);

  // Listen to merged photos from server
  useEffect(() => {
    const handlePhotosMerged = (message: any) => {
      console.log("[Host] Received merged photos from server:", message);

      if (message.photos && Array.isArray(message.photos)) {
        // Create photos array with merged images
        const API_URL =
          process.env.NEXT_PUBLIC_API_URL || "http://localhost:3001";
        const mergedPhotos = message.photos
          .sort((a: any, b: any) => a.photoNumber - b.photoNumber)
          .map((photo: any) => `${API_URL}${photo.mergedImageUrl}`);

        setMergedPhotos(mergedPhotos);
        console.log(`[Host] Displayed ${mergedPhotos.length} merged photos`);
      }
    };

    on("photos-merged", handlePhotosMerged);

    return () => {
      // Cleanup if needed
    };
  }, [on, setMergedPhotos]);

  // Photo capture logic
  const startPhotoSession = () => {
    if (!store.roomId) return;

    console.log('[Host] ========== PHOTO SESSION START (Individual Recording) ==========');
    console.log('[Host] Session settings:');
    console.log('[Host]  - recordingDuration:', recordingDuration, 'seconds (ì˜ìƒ ë…¹í™” ì‹œê°„ = ì´¬ì˜ ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œê°„)');
    console.log('[Host]  - captureInterval:', captureInterval, 'seconds (ì‚¬ì§„ ì´¬ì˜ í›„ ë‹¤ìŒ ì‚¬ì§„ê¹Œì§€ ëŒ€ê¸° ì‹œê°„)');
    console.log('[Host] Mode: Individual segment recording (no FFmpeg splitting needed!)');
    console.log('[Host] ================================================');

    setIsCapturing(true);
    resetCapture();
    setRecordedSegments([]); // Clear previous segments
    setCurrentlyRecording(null);

    // Send session settings to server
    const sessionSettings = {
      type: "session-settings" as const,
      roomId: store.roomId,
      settings: {
        recordingDuration,
        captureInterval,
      },
    };
    console.log('[Host] Sending session settings to server:', sessionSettings);
    sendMessage(sessionSettings);

    sendMessage({
      type: "photo-session-start",
      roomId: store.roomId,
    });

    // Start first photo after a brief delay
    setTimeout(() => {
      takePhoto(1);
    }, 1000);
  };

  // Photo selection is Guest-only, Host just displays Guest's selections

  const takePhoto = (photoNumber: number) => {
    if (!store.roomId || photoNumber > 8) {
      setIsCapturing(false);
      return;
    }

    console.log('[Host] ========== Taking photo', photoNumber, '==========');
    console.log('[Host] Starting individual video recording for this segment');

    // Start individual video recording for this photo
    if (videoRecorderRef.current) {
      setCurrentlyRecording(photoNumber);

      const recordingStartTime = Date.now();

      try {
        videoRecorderRef.current.startRecording(
          photoNumber,
          recordingDuration * 1000, // Convert seconds to milliseconds
          (blob, completedPhotoNumber) => {
            // Recording complete callback
            const recordingEndTime = Date.now();
            const duration = (recordingEndTime - recordingStartTime) / 1000;

            console.log(`[Host] âœ… Video segment ${completedPhotoNumber} recorded:`, {
              size: `${(blob.size / 1024 / 1024).toFixed(2)} MB`,
              duration: `${duration.toFixed(2)}s`
            });

            // Create VideoSegment
            const segment: VideoSegment = {
              photoNumber: completedPhotoNumber,
              blob,
              url: URL.createObjectURL(blob),
              startTime: 0, // Each segment starts at 0
              endTime: duration,
            };

            // Save segment
            setRecordedSegments(prev => {
              const newSegments = [...prev, segment].sort((a, b) => a.photoNumber - b.photoNumber);
              console.log(`[Host] Total segments recorded: ${newSegments.length}/8`);
              return newSegments;
            });

            setCurrentlyRecording(null);
          }
        );

        console.log(`[Host] Recording started for photo ${photoNumber} (${recordingDuration}s)`);
      } catch (error) {
        console.error('[Host] Failed to start recording:', error);
        setCurrentlyRecording(null);
      }
    }

    // Countdown before taking photo (matches recording duration)
    let count = recordingDuration;
    setCountdown(count);
    console.log('[Host] Starting countdown from', count, 'seconds');

    // Send countdown ticks
    sendMessage({
      type: "countdown-tick",
      roomId: store.roomId,
      count,
      photoNumber,
    });

    const interval = setInterval(() => {
      count--;
      console.log('[Host] Countdown:', count);

      if (count <= 0) {
        clearInterval(interval);
        setCountdown(null);

        // Send final countdown
        sendMessage({
          type: "countdown-tick",
          roomId: store.roomId!,
          count: 0,
          photoNumber,
        });

        // Capture the photo
        capturePhoto(photoNumber);
      } else {
        setCountdown(count);
        sendMessage({
          type: "countdown-tick",
          roomId: store.roomId!,
          count,
          photoNumber,
        });
      }
    }, 1000);
  };

  const capturePhoto = async (photoNumber: number) => {
    console.log(`[Host] ğŸ“¸ Capturing photo ${photoNumber}`);

    // Send capture signal
    if (store.roomId) {
      sendMessage({
        type: "capture-now",
        roomId: store.roomId,
        photoNumber,
      });
    }

    // Capture ONLY local canvas (Host's chroma key layer) for high-quality server-side merge
    const localCanvas = localCanvasRef.current;
    if (localCanvas && store.roomId) {
      try {
        await captureAndUpload({
          photoNumber,
          canvasOrVideo: localCanvas,
          isCanvas: true,
        });

        // Take next photo or finish session
        if (photoNumber < 8) {
          console.log('[Host] Photo', photoNumber, 'captured successfully');
          console.log('[Host] â±ï¸  Waiting', captureInterval, 'seconds before next photo');
          setTimeout(() => {
            console.log('[Host] Starting photo', photoNumber + 1);
            takePhoto(photoNumber + 1);
          }, captureInterval * 1000);
        } else {
          // Last photo
          console.log('[Host] âœ… Last photo captured!');
          setIsCapturing(false);
          startProcessing();
          console.log("[Host] Photo session complete, waiting for merge...");
        }
      } catch (error) {
        console.error(`[Host] Failed to upload photo ${photoNumber}:`, error);
        alert(`ì‚¬ì§„ ${photoNumber} ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.`);
      }
    }
  };

  const handleGenerateFrame = async () => {
    if (peerSelectedPhotos.length !== 4) {
      alert('Guestê°€ 4ì¥ì˜ ì‚¬ì§„ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.');
      return;
    }

    setIsGeneratingFrame(true);
    try {
      await downloadPhotoFrame(photos, peerSelectedPhotos, store.roomId || 'frame', aspectRatio);
      console.log('[Host] Photo frame generated and downloaded');
    } catch (error) {
      console.error('[Host] Failed to generate frame:', error);
      alert('í”„ë ˆì„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsGeneratingFrame(false);
    }
  };

  // Note: handleSplitVideo removed - no longer needed with individual recording!

  const autoComposeAndUploadVideo = async (selectedPhotoIndices: number[]) => {
    if (!store.roomId || !store.userId) {
      console.error('[Host] Missing roomId or userId');
      return;
    }

    // Check if we have recorded segments
    if (recordedSegments.length === 0) {
      console.error('[Host] No recorded segments available');
      alert('ë…¹í™”ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    // Get selected segments (indices are 0-based, photoNumber is 1-based)
    const selectedSegments = selectedPhotoIndices
      .map(index => recordedSegments.find(seg => seg.photoNumber === index + 1))
      .filter((seg): seg is VideoSegment => seg !== undefined);

    if (selectedSegments.length !== 4) {
      console.error(`[Host] Failed to find all segments (${selectedSegments.length}/4)`);
      alert(`ì„ íƒí•œ ì‚¬ì§„ ì¤‘ ${4 - selectedSegments.length}ê°œì˜ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`);
      return;
    }

    console.log('[Host] ğŸš€ Auto-composing with WebGL GPU (ì¬ì¸ì½”ë”© ì—†ìŒ!)');
    console.log('[Host] Auto-composing video frame with segments:', selectedSegments.map(s => s.photoNumber));

    setIsComposing(true);
    setComposeProgress('WebGL GPU í•©ì„± ì‹œì‘...');

    try {
      // Convert VideoSegment to VideoSource
      const videoSources: VideoSource[] = selectedSegments.map(seg => ({
        blob: seg.blob,
        startTime: seg.startTime,
        endTime: seg.endTime,
        photoNumber: seg.photoNumber,
      }));

      // Use WebGL composition (GPU-accelerated, no re-encoding!)
      const composedBlob = await composeVideoWithWebGL(
        videoSources,
        {
          width: ASPECT_RATIOS[aspectRatio].width,
          height: ASPECT_RATIOS[aspectRatio].height,
          frameRate: 24,
        },
        (progress) => {
          setComposeProgress(progress);
          console.log('[Host] WebGL compose progress:', progress);
        }
      );

      console.log('[Host] Composition complete, uploading to server...');
      setComposeProgress('ì„œë²„ì— ì—…ë¡œë“œ ì¤‘...');

      // Upload to server
      const formData = new FormData();
      formData.append('video', composedBlob, 'video-frame.mp4');
      formData.append('roomId', store.roomId);
      formData.append('userId', store.userId);

      const API_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:3001';
      const response = await fetch(`${API_URL}/api/video/upload`, {
        method: 'POST',
        headers: getApiHeadersMultipart(),
        body: formData,
      });

      if (!response.ok) {
        throw new Error('Upload failed');
      }

      const result = await response.json();
      console.log('[Host] Upload complete:', result);

      // Save composed video locally
      const url = URL.createObjectURL(composedBlob);
      if (composedVideo) {
        URL.revokeObjectURL(composedVideo.url);
      }
      setComposedVideo({ blob: composedBlob, url });

      setComposeProgress('ì™„ë£Œ!');
      alert('ì˜ìƒ í”„ë ˆì„ì´ ìƒì„±ë˜ì–´ Guestì—ê²Œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰');

    } catch (error) {
      console.error('[Host] Failed to compose/upload video:', error);
      alert('ì˜ìƒ í•©ì„± ë˜ëŠ” ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ' + (error instanceof Error ? error.message : ''));
    } finally {
      setIsComposing(false);
      setTimeout(() => setComposeProgress(''), 2000);
    }
  };

  const handleComposeVideoFrame = async () => {
    if (peerSelectedPhotos.length !== 4) {
      alert('Guestê°€ 4ì¥ì˜ ì‚¬ì§„ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.');
      return;
    }

    // Check if we have recorded segments
    if (recordedSegments.length === 0) {
      alert('ë…¹í™”ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. ì´¬ì˜ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.');
      return;
    }

    // Get selected segments (Guest's selection is 0-indexed, photoNumber is 1-based)
    const selectedSegments = peerSelectedPhotos
      .map(index => recordedSegments.find(seg => seg.photoNumber === index + 1))
      .filter((seg): seg is VideoSegment => seg !== undefined);

    if (selectedSegments.length !== 4) {
      alert(`ì„ íƒí•œ ì‚¬ì§„ ì¤‘ ${4 - selectedSegments.length}ê°œì˜ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`);
      return;
    }

    console.log('[Host] ğŸš€ WebGL GPU í•©ì„± ì‹œì‘ (ì¬ì¸ì½”ë”© ì—†ìŒ!)');
    console.log('[Host] Composing video frame with segments:', selectedSegments.map(s => s.photoNumber));

    setIsComposing(true);
    setComposeProgress('WebGL GPU í•©ì„± ì‹œì‘...');

    try {
      // Convert VideoSegment to VideoSource
      const videoSources: VideoSource[] = selectedSegments.map(seg => ({
        blob: seg.blob,
        startTime: seg.startTime,
        endTime: seg.endTime,
        photoNumber: seg.photoNumber,
      }));

      // Use WebGL composition (GPU-accelerated, no re-encoding!)
      const composedBlob = await composeVideoWithWebGL(
        videoSources,
        {
          width: ASPECT_RATIOS[aspectRatio].width,
          height: ASPECT_RATIOS[aspectRatio].height,
          frameRate: 24,
        },
        (progress) => {
          setComposeProgress(progress);
          console.log('[Host] WebGL compose progress:', progress);
        }
      );

      const url = URL.createObjectURL(composedBlob);

      // Cleanup previous composed video
      if (composedVideo) {
        URL.revokeObjectURL(composedVideo.url);
      }

      setComposedVideo({ blob: composedBlob, url });
      console.log('[Host] âœ… WebGL composition complete (no re-encoding!):', {
        size: `${(composedBlob.size / 1024 / 1024).toFixed(2)} MB`,
      });

      alert('âœ¨ ì˜ìƒ í”„ë ˆì„ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! (WebGL GPU í•©ì„± - ì¬ì¸ì½”ë”© ì—†ìŒ!)');
    } catch (error) {
      console.error('[Host] Failed to compose video with WebGL:', error);
      alert('ì˜ìƒ í•©ì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ' + (error instanceof Error ? error.message : ''));
    } finally {
      setIsComposing(false);
      setComposeProgress('');
    }
  };

  // Auto-start camera when room is created
  useEffect(() => {
    if (store.roomId && !isCameraActive && !localStream) {
      console.log("[Host] Room created, auto-starting camera");
      startCamera();
    }
  }, [store.roomId]);

  // Create offer when peer joins
  useEffect(() => {
    if (store.peerId && localStream) {
      console.log(
        "[Host] Peer joined, waiting before creating offer:",
        store.peerId
      );
      // Wait a bit for guest to initialize their stream
      const timer = setTimeout(() => {
        console.log("[Host] Creating offer for peer:", store.peerId);
        createOffer().catch((error) => {
          console.error("[Host] Failed to create offer:", error);
        });
      }, 1000); // 1 second delay to ensure guest is ready

      return () => clearTimeout(timer);
    }
  }, [store.peerId, localStream, createOffer]);

  // Cleanup - only on component unmount
  useEffect(() => {
    return () => {
      console.log('[Host] Component unmounting - cleaning up resources');
      stopCamera();
      if (videoRecorderRef.current) {
        videoRecorderRef.current.dispose();
      }
    };
  }, []); // Empty dependency - cleanup only on unmount

  // Cleanup URLs when segments/video change
  useEffect(() => {
    return () => {
      // Cleanup segment URLs when they change
      if (recordedSegments.length > 0) {
        recordedSegments.forEach(segment => {
          URL.revokeObjectURL(segment.url);
        });
      }
    };
  }, [recordedSegments]);

  useEffect(() => {
    return () => {
      // Cleanup composed video URL when it changes
      if (composedVideo) {
        URL.revokeObjectURL(composedVideo.url);
      }
    };
  }, [composedVideo]);

  console.log("HOST: isProcessing", isProcessing);

  return (
    <div className="min-h-screen bg-light text-dark p-8">
      <FlashOverlay show={showFlash} />

      <div className="max-w-6xl mx-auto">
        <div className="mb-8">
          <h1 className="text-3xl font-bold mb-4 text-dark">
            Host (VTuber with Chroma Key)
          </h1>
          <div className="space-y-3">
            {store.roomId && (
              <div className="bg-primary px-6 py-3 rounded-lg inline-block shadow-md">
                <span className="text-sm opacity-90 text-white">Room ID:</span>
                <span className="text-2xl font-bold ml-2 text-white">{store.roomId}</span>
              </div>
            )}
            <ConnectionStatus
              isConnected={isConnected}
              peerId={store.peerId}
              remoteStream={remoteStream}
              role="host"
            />
          </div>
        </div>

        {/* Controls */}
        <div className="bg-white border-2 border-neutral rounded-lg p-6 mb-6 shadow-md">
          <div className="flex flex-wrap gap-4 items-center mb-4">
            {!isCameraActive ? (
              <button
                onClick={startCamera}
                disabled={!isConnected}
                className="px-6 py-3 bg-primary hover:bg-primary-dark text-white rounded-lg font-semibold transition shadow-md disabled:opacity-50"
              >
                {isConnected ? "ì¹´ë©”ë¼ ì‹œì‘" : "ì—°ê²° ì¤‘..."}
              </button>
            ) : (
              <button
                onClick={stopCamera}
                className="px-6 py-3 bg-secondary hover:bg-secondary-dark text-white rounded-lg font-semibold transition shadow-md"
              >
                ì¹´ë©”ë¼ ì¤‘ì§€
              </button>
            )}

            {isCameraActive && (
              <button
                onClick={() => setChromaKeyEnabled(!chromaKeyEnabled)}
                className={`px-6 py-3 rounded-lg font-semibold transition shadow-md ${
                  chromaKeyEnabled
                    ? "bg-primary hover:bg-primary-dark text-white"
                    : "bg-neutral hover:bg-neutral-dark text-dark"
                }`}
              >
                í¬ë¡œë§ˆí‚¤: {chromaKeyEnabled ? "ON" : "OFF"}
              </button>
            )}

            {isCameraActive && (
              <button
                onClick={toggleHostFlip}
                className={`px-4 py-2 rounded-lg font-semibold text-sm transition ${
                  hostFlipHorizontal
                    ? 'bg-primary hover:bg-primary-dark text-white shadow-md'
                    : 'bg-neutral hover:bg-neutral-dark text-dark'
                }`}
                title="ë‚´ í™”ë©´ ì¢Œìš° ë°˜ì „"
              >
                {hostFlipHorizontal ? 'â†”ï¸ Host ë°˜ì „ ON' : 'â†”ï¸ Host ë°˜ì „ OFF'}
              </button>
            )}
          </div>

          {/* Chroma key settings */}
          {isCameraActive && chromaKeyEnabled && (
            <div className="space-y-4">
              <div>
                <label className="block text-sm font-medium mb-2">
                  ë¯¼ê°ë„ (Sensitivity): {sensitivity}
                </label>
                <input
                  type="range"
                  min="0"
                  max="100"
                  value={sensitivity}
                  onChange={(e) => setSensitivity(Number(e.target.value))}
                  className="w-full"
                />
              </div>
              <div>
                <label className="block text-sm font-medium mb-2">
                  ë¶€ë“œëŸ¬ì›€ (Smoothness): {smoothness}
                </label>
                <input
                  type="range"
                  min="0"
                  max="100"
                  value={smoothness}
                  onChange={(e) => setSmoothness(Number(e.target.value))}
                  className="w-full"
                />
              </div>
            </div>
          )}
        </div>

        {/* Timer settings */}
        {remoteStream && (
          <div className="bg-white border-2 border-neutral rounded-lg p-6 mb-6 shadow-md">
            <h2 className="text-xl font-semibold mb-4 text-dark">ì´¬ì˜ ì„¤ì •</h2>
            <div className="space-y-4">
              <div>
                <label className="block text-sm font-medium mb-2">
                  ë…¹í™” ì‹œê°„ (Recording Duration): {recordingDuration}ì´ˆ
                </label>
                <input
                  type="range"
                  min="5"
                  max="30"
                  value={recordingDuration}
                  onChange={(e) => setRecordingDuration(Number(e.target.value))}
                  disabled={isCapturing}
                  className="w-full disabled:opacity-50"
                />
                <p className="text-xs text-gray-400 mt-1">
                  ê° ì‚¬ì§„ ì´¬ì˜ ì‹œ ë…¹í™”í•  ì˜ìƒì˜ ê¸¸ì´ ë° ì´¬ì˜ ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œê°„ (5~30ì´ˆ)
                </p>
              </div>
              <div>
                <label className="block text-sm font-medium mb-2">
                  ì´¬ì˜ ê°„ê²© (Capture Interval): {captureInterval}ì´ˆ
                </label>
                <input
                  type="range"
                  min="1"
                  max="10"
                  value={captureInterval}
                  onChange={(e) => setCaptureInterval(Number(e.target.value))}
                  disabled={isCapturing}
                  className="w-full disabled:opacity-50"
                />
                <p className="text-xs text-gray-400 mt-1">
                  ì‚¬ì§„ ì´¬ì˜ ì‚¬ì´ì˜ ëŒ€ê¸° ì‹œê°„ (1~10ì´ˆ)
                </p>
              </div>
            </div>
          </div>
        )}

        {/* Aspect Ratio settings */}
        {remoteStream && (
          <div className="bg-white border-2 border-neutral rounded-lg p-6 mb-6 shadow-md">
            <h2 className="text-xl font-semibold mb-4 text-dark">í™”ë©´ ë¹„ìœ¨ ì„¤ì •</h2>
            <div className="space-y-4">
              <div>
                <label className="block text-sm font-medium mb-3">
                  ì´¬ì˜ ë¹„ìœ¨ (Aspect Ratio): {ASPECT_RATIOS[aspectRatio].label}
                </label>
                <div className="grid grid-cols-5 gap-3">
                  {(Object.keys(ASPECT_RATIOS) as AspectRatio[]).map((ratio) => (
                    <button
                      key={ratio}
                      onClick={() => updateAspectRatio(ratio)}
                      disabled={isCapturing}
                      className={`px-4 py-3 rounded-lg font-semibold text-sm transition shadow-md disabled:opacity-50 disabled:cursor-not-allowed ${
                        aspectRatio === ratio
                          ? 'bg-primary hover:bg-primary-dark text-white'
                          : 'bg-neutral hover:bg-neutral-dark text-dark'
                      }`}
                    >
                      {ratio}
                    </button>
                  ))}
                </div>
                <p className="text-xs text-gray-400 mt-3">
                  ë¯¸ë¦¬ë³´ê¸°, ì‚¬ì§„ ì´¬ì˜, ì˜ìƒ ë…¹í™”, í•©ì„± ë“± ëª¨ë“  ê³¼ì •ì— ì ìš©ë©ë‹ˆë‹¤
                </p>
                <div className="mt-2 px-4 py-2 bg-neutral/30 rounded-lg">
                  <p className="text-xs text-dark/70 font-medium">
                    í•´ìƒë„: {ASPECT_RATIOS[aspectRatio].width} Ã— {ASPECT_RATIOS[aspectRatio].height}
                  </p>
                </div>
              </div>
            </div>
          </div>
        )}

        {/* Video display */}
        <div className="grid grid-cols-1 gap-6">
          {/* Hidden video elements for processing */}
          <video
            ref={remoteVideoRef}
            autoPlay
            playsInline
            className="absolute opacity-0 pointer-events-none"
          />
          <video
            ref={localVideoRef}
            autoPlay
            playsInline
            muted
            className="absolute opacity-0 pointer-events-none"
          />

          {/* Main view - Show own video when alone, composite when connected */}
          <div className="bg-gray-800 rounded-lg p-4">
            <h2 className="text-xl font-semibold mb-4">
              {remoteStream ? "í•©ì„± í™”ë©´ (Guest + Host)" : "ë‚´ ì˜ìƒ (Host)"}
            </h2>
            {/* 1:1 Container to prevent layout shift */}
            <div className="relative rounded-lg overflow-hidden aspect-square">
              <div
                className="absolute inset-0"
                style={{
                  backgroundImage: `
                    linear-gradient(45deg, #333 25%, transparent 25%),
                    linear-gradient(-45deg, #333 25%, transparent 25%),
                    linear-gradient(45deg, transparent 75%, #333 75%),
                    linear-gradient(-45deg, transparent 75%, #333 75%)
                  `,
                  backgroundSize: "20px 20px",
                  backgroundPosition: "0 0, 0 10px, 10px -10px, -10px 0px",
                }}
              />

              {/* Canvas container with dynamic aspect ratio */}
              <div className="absolute inset-0 flex items-center justify-center">
                {/* Show own chroma key canvas when alone */}
                <canvas
                  ref={localCanvasRef}
                  className={`absolute max-w-full max-h-full transition-opacity ${
                    remoteStream ? "opacity-0" : "opacity-100"
                  }`}
                  style={{
                    transform: hostFlipHorizontal ? 'scaleX(-1)' : 'scaleX(1)',
                    aspectRatio: aspectRatio.replace(':', '/'),
                  }}
                />

                {/* Show composite when connected */}
                <canvas
                  ref={compositeCanvasRef}
                  className={`absolute max-w-full max-h-full transition-opacity ${
                    !remoteStream ? "opacity-0" : "opacity-100"
                  }`}
                  style={{
                    aspectRatio: aspectRatio.replace(':', '/'),
                  }}
                />
              </div>

              <CountdownOverlay countdown={countdown} />

              {!isCameraActive && (
                <div className="absolute inset-0 flex items-center justify-center text-gray-500 bg-black">
                  ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”
                </div>
              )}
            </div>
          </div>

          {/* Photo capture panel */}
          {remoteStream && (
            <div className="bg-white border-2 border-neutral rounded-lg p-6 mt-6 shadow-md">
              <h2 className="text-xl font-semibold mb-4 text-dark">ì‚¬ì§„ ì´¬ì˜</h2>

              <div className="mb-4">
                <div className="flex items-center justify-between mb-2">
                  <div className="text-lg text-dark font-semibold">ì´¬ì˜: {photoCount} / 8</div>
                  {currentlyRecording !== null && (
                    <div className="flex items-center gap-2 text-sm text-primary font-medium">
                      <div className="w-2 h-2 bg-primary rounded-full animate-pulse"></div>
                      ì˜ìƒ #{currentlyRecording} ë…¹í™” ì¤‘
                    </div>
                  )}
                </div>
                <button
                  onClick={startPhotoSession}
                  disabled={!remoteStream || isCapturing}
                  className="w-full px-6 py-3 bg-primary hover:bg-primary-dark text-white rounded-lg font-semibold transition shadow-md disabled:opacity-50 disabled:cursor-not-allowed"
                >
                  {isCapturing ? "ì´¬ì˜ ì¤‘..." : "ì´¬ì˜ ì‹œì‘ (ì‚¬ì§„ + ì˜ìƒ)"}
                </button>
              </div>

              <PhotoThumbnailGrid photos={photos} totalSlots={8} />
            </div>
          )}

          <ProcessingIndicator show={isProcessing} />

          <PhotoSelectionPanel
            photos={photos}
            selectedPhotos={[]}
            onGenerateFrame={handleGenerateFrame}
            readOnly={true}
            role="host"
            peerSelectedPhotos={peerSelectedPhotos}
            isGenerating={isGeneratingFrame}
          />

          {/* Video Frame Composition */}
          {recordedSegments.length >= 4 && peerSelectedPhotos.length === 4 && (
            <div className="bg-white border-2 border-neutral rounded-lg p-6 mt-6 shadow-md">
              <h2 className="text-2xl font-semibold mb-4 text-dark">ğŸš€ ì˜ìƒ í”„ë ˆì„ ìƒì„± (WebGL GPU í•©ì„±)</h2>
              <p className="text-dark/70 mb-4">
                Guestê°€ ì„ íƒí•œ 4ê°œì˜ ì‚¬ì§„ì— í•´ë‹¹í•˜ëŠ” ì˜ìƒì„ 2x2 ê·¸ë¦¬ë“œë¡œ í•©ì„±í•©ë‹ˆë‹¤.
                <br />
                <span className="text-primary font-semibold">âš¡ GPU ê°€ì† - ì¬ì¸ì½”ë”© ì—†ì´ ì‹¤ì‹œê°„ í•©ì„±!</span>
              </p>

              {isComposing && (
                <div className="bg-neutral/30 border border-neutral rounded-lg p-4 mb-4">
                  <div className="flex items-center gap-3">
                    <div className="animate-spin rounded-full h-6 w-6 border-b-2 border-primary"></div>
                    <div className="text-sm text-dark font-medium">
                      {composeProgress || 'ì²˜ë¦¬ ì¤‘...'}
                    </div>
                  </div>
                </div>
              )}

              <button
                onClick={handleComposeVideoFrame}
                disabled={isComposing}
                className="w-full px-6 py-4 bg-primary hover:bg-primary-dark text-white rounded-lg font-semibold text-lg transition shadow-md disabled:opacity-50 disabled:cursor-not-allowed"
              >
                {isComposing ? 'âš¡ GPU í•©ì„± ì¤‘...' : 'âš¡ ì˜ìƒ í”„ë ˆì„ ìƒì„± (WebGL GPU)'}
              </button>

              {composedVideo && (
                <div className="mt-4">
                  <div className="bg-dark rounded-lg overflow-hidden mb-4 border-2 border-neutral">
                    <video
                      src={composedVideo.url}
                      controls
                      className="w-full aspect-video bg-black"
                    />
                  </div>
                  <div className="bg-neutral/30 border border-neutral rounded-lg p-4">
                    <div className="flex items-center justify-between mb-3">
                      <span className="text-sm font-semibold text-primary">âš¡ WebGL í•©ì„± ì™„ë£Œ</span>
                      <span className="text-xs text-dark/70 font-medium">
                        WebM Â· {(composedVideo.blob.size / 1024 / 1024).toFixed(2)} MB
                      </span>
                    </div>
                    <button
                      onClick={() => {
                        const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, -5);
                        downloadWebGLComposedVideo(composedVideo.blob, `vshot-frame-${store.roomId}-${timestamp}.webm`);
                      }}
                      className="w-full px-4 py-3 bg-secondary hover:bg-secondary-dark text-white rounded-lg font-semibold transition shadow-md"
                    >
                      ğŸ“¥ ì˜ìƒ í”„ë ˆì„ ë‹¤ìš´ë¡œë“œ (WebM - WebGL í•©ì„±)
                    </button>
                    <p className="text-xs text-dark/70 mt-3 text-center">
                      âš¡ WebGL GPUë¡œ ì‹¤ì‹œê°„ í•©ì„± - FFmpeg ì¬ì¸ì½”ë”© ì—†ìŒ!
                      <br />
                      ğŸ’¡ Guestê°€ ì„ íƒí•œ 4ê°œ ì˜ìƒì„ 2x2 ê·¸ë¦¬ë“œë¡œ í•©ì„±í•œ WebM íŒŒì¼ì…ë‹ˆë‹¤.
                    </p>
                  </div>
                </div>
              )}
            </div>
          )}

          {/* Recorded video segments panel */}
          {recordedSegments.length > 0 && !isCapturing && (
            <div className="bg-white border-2 border-neutral rounded-lg p-6 mt-6 shadow-md">
              <div className="flex items-center justify-between mb-4">
                <h2 className="text-2xl font-semibold text-dark">âš¡ ë…¹í™”ëœ ì˜ìƒ ì„¸ê·¸ë¨¼íŠ¸ (ê°œë³„ ë…¹í™”)</h2>
                <div className="px-3 py-1 bg-primary text-white rounded-full text-sm font-semibold shadow-md">
                  âœ“ {recordedSegments.length}ê°œ êµ¬ê°„
                </div>
              </div>
              <p className="text-dark/70 mb-4">
                ê° ì‚¬ì§„ ì´¬ì˜ ì‹œ ê°œë³„ë¡œ ë…¹í™”ëœ ì˜ìƒ (FFmpeg ë¶„í•  ë¶ˆí•„ìš”!)
              </p>

              {/* Video grid */}
              <div className="grid grid-cols-4 gap-4 mb-4">
                {recordedSegments.map((segment) => (
                  <div key={segment.photoNumber} className="bg-neutral/30 border border-neutral rounded-lg overflow-hidden">
                    <video
                      src={segment.url}
                      controls
                      className="w-full aspect-video bg-black"
                    />
                    <div className="p-3">
                      <div className="text-sm font-semibold mb-1 text-dark">
                        ì˜ìƒ #{segment.photoNumber}
                      </div>
                      <div className="text-xs text-dark/70 mb-2 font-medium">
                        {segment.startTime.toFixed(1)}s - {segment.endTime.toFixed(1)}s
                        <br />
                        {(segment.blob.size / 1024 / 1024).toFixed(2)} MB
                      </div>
                      <button
                        onClick={() => {
                          const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, -5);
                          downloadVideo(segment.blob, `vshot-video-${store.roomId}-${segment.photoNumber}-${timestamp}.webm`);
                        }}
                        className="w-full px-3 py-2 bg-secondary hover:bg-secondary-dark text-white rounded text-sm font-semibold transition shadow-md"
                      >
                        ë‹¤ìš´ë¡œë“œ
                      </button>
                    </div>
                  </div>
                ))}
              </div>

              {/* Download all button */}
              <button
                onClick={() => {
                  if (store.roomId) {
                    downloadSegments(recordedSegments, store.roomId);
                  }
                }}
                className="w-full px-6 py-3 bg-primary hover:bg-primary-dark text-white rounded-lg font-semibold transition shadow-md"
              >
                âš¡ ëª¨ë“  êµ¬ê°„ ë‹¤ìš´ë¡œë“œ ({recordedSegments.length}ê°œ)
              </button>
              <div className="mt-4 bg-primary/10 border-2 border-primary rounded-lg p-4">
                <p className="text-xs text-dark font-medium">
                  âœ… ê°œë³„ ë…¹í™” ë°©ì‹ìœ¼ë¡œ FFmpeg ë¶„í•  ë‹¨ê³„ê°€ ì™„ì „íˆ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤!
                  <br />
                  âš¡ ì˜ìƒ í•©ì„± ì‹œê°„ì´ 90% ë‹¨ì¶•ë©ë‹ˆë‹¤.
                </p>
              </div>
            </div>
          )}
        </div>

        {/* Usage info */}
        {!store.peerId && isCameraActive && (
          <div className="mt-8 bg-white border-2 border-neutral rounded-lg p-6 shadow-md">
            <h2 className="text-xl font-semibold mb-4 text-dark">ì•ˆë‚´</h2>
            <ul className="list-disc list-inside space-y-2 text-dark/80">
              <li>Room IDë¥¼ Guestì—ê²Œ ê³µìœ í•˜ì„¸ìš”</li>
              <li>Guestê°€ ì…ì¥í•˜ë©´ ìë™ìœ¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤</li>
              <li>í¬ë¡œë§ˆí‚¤ë¥¼ í™œì„±í™”í•˜ì—¬ ë…¹ìƒ‰ ë°°ê²½ì„ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤</li>
            </ul>
          </div>
        )}
      </div>
    </div>
  );
}
